{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashwinr/MONAI_tutorials/blob/main/MEDMNIST_Pneumonia_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SHDTBOX3soX"
      },
      "source": [
        "# MEDMNIST Pneumonia Classification\n",
        "\n",
        "Objectives:\n",
        "Develop a medical image classification algorithm that enables accurate prediction of pneumonia in chest X-ray.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY2gvpJb1cSh"
      },
      "source": [
        "## Installing MONAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsV81_ErKXe6"
      },
      "outputs": [],
      "source": [
        "!pip show monai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlQOK-cAU_sg"
      },
      "outputs": [],
      "source": [
        "!pip install monai[all]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZjPdajL1mn0"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZouMxrCoucWM"
      },
      "outputs": [],
      "source": [
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXWqFxqCured"
      },
      "outputs": [],
      "source": [
        "from medmnist import PneumoniaMNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onsTQY7G2F-Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dir_path = os.getcwd()\n",
        "print(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF0c2KIZuvNU"
      },
      "outputs": [],
      "source": [
        "data_train = PneumoniaMNIST(root=dir_path, split='train',download=True)\n",
        "data_val = PneumoniaMNIST(split='val', download=True)\n",
        "data_test = PneumoniaMNIST(split='test', download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg2Dr26R6H30"
      },
      "outputs": [],
      "source": [
        "print(data_train.info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwuLUQtdu0Xk"
      },
      "outputs": [],
      "source": [
        "!unzip /content/pneumoniamnist.npz -d /content/pneumoniamnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nol62FxyIHM"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_dir=\"/content/pneumoniamnist\"\n",
        "print(data_dir)\n",
        "\n",
        "for files in os.listdir(data_dir):\n",
        "    print(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STwhxmzwHMi5"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkU3dG4Y4rKQ"
      },
      "source": [
        "* Below cell prints the total number of classes in train dataset, class names, and the number of images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgGHGJUMHMi6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "train_images = np.load('/content/pneumoniamnist/train_images.npy')\n",
        "train_label = np.load('/content/pneumoniamnist/train_labels.npy')\n",
        "\n",
        "print(\"train_images shape:\", train_images.shape)\n",
        "print(\"train_labels shape:\", train_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y63oif_H6kja"
      },
      "outputs": [],
      "source": [
        "from monai.data import Dataset                                      # Prepare data for MONAI Dataset\n",
        "\n",
        "train_files = [{'image': img} for img in train_images]\n",
        "print(len(train_files))\n",
        "\n",
        "train_dataset = Dataset(data=train_files, transform=None)           # Create a MONAI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G94XhSMs7j8K"
      },
      "outputs": [],
      "source": [
        "print(f\"The length of train dataset is: {len(train_dataset)}\")\n",
        "print(f\"The size of the image is: {train_dataset[0]['image'].shape} with type {type(train_dataset[0]['image'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muIMIedz8SF4"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s2atMRz8UNl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Select 9 random images from the training dataset\n",
        "random_indices = random.sample(range(len(train_dataset)), 9)\n",
        "images = [train_dataset[i]['image'] for i in random_indices]\n",
        "labels = [train_label[i].item() for i in random_indices]  # Assuming train_label contains labels\n",
        "\n",
        "# Create a 3x3 subplot grid\n",
        "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
        "\n",
        "# Plot each image in the subplot with title\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(np.transpose(images[i]), cmap='gray')\n",
        "    ax.set_title(f\"Label: {labels[i]}\")  # Add title with label\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data distribution"
      ],
      "metadata": {
        "id": "JynNFXSFpGml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class in the training set\n",
        "train_class_counts = np.bincount(train_label.flatten().astype(int))\n",
        "\n",
        "# Assuming class 0 is 'normal' and class 1 is 'pneumonia'\n",
        "class_names = ['normal', 'pneumonia']\n",
        "\n",
        "\n",
        "# Repeat the process for validation and test sets\n",
        "val_labels = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "test_labels = np.load('/content/pneumoniamnist/test_labels.npy')\n",
        "\n",
        "val_class_counts = np.bincount(val_labels.flatten().astype(int))\n",
        "test_class_counts = np.bincount(test_labels.flatten().astype(int))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ... (your existing code to load and process data) ...\n",
        "\n",
        "# Define bar width and positions\n",
        "bar_width = 0.25\n",
        "x_positions = np.arange(len(class_names))\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar(x_positions - bar_width, train_class_counts, width=bar_width, label='Train', color='skyblue')\n",
        "plt.bar(x_positions, val_class_counts, width=bar_width, label='Validation', color='orange')\n",
        "plt.bar(x_positions + bar_width, test_class_counts, width=bar_width, label='Test', color='lightgreen')\n",
        "\n",
        "# Set labels, title, and legend\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Data Distribution Across Datasets')\n",
        "plt.xticks(x_positions, class_names)  # Set x-axis tick labels\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bcKXIUUtpKh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdVzPjZBBSXR"
      },
      "source": [
        "### Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHtiw3-ABUhU"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,  # Import LoadImaged for dictionary-based input\n",
        "    RandRotate,\n",
        "    RandFlip,\n",
        "    ToTensor,\n",
        "    EnsureChannelFirstd, # Use EnsureChannelFirstd to work with dictionary\n",
        "    ScaleIntensityd, # Use ScaleIntensityd to work with dictionary\n",
        "    EnsureTyped, # Add this\n",
        "    Resized,\n",
        "    BorderPadd # Use BorderPadd for dictionary-based input\n",
        ")\n",
        "from monai.data import Dataset, NumpyReader\n",
        "\n",
        "# Define transforms for training data\n",
        "train_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),  # Add channel dimension to the image data using the 'image' key\n",
        "    ScaleIntensityd(keys=['image']),  # Rescale image pixel values using the 'image' key\n",
        "    EnsureTyped(keys=['image']),\n",
        "    # Resized(keys=[\"image\"],spatial_size=(32,32)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2, 2]), # Use a list of two integers for padding (height, width) or a single integer for both.\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = Dataset(data=train_dataset, transform=train_transforms)\n",
        "train_label = np.load('/content/pneumoniamnist/train_labels.npy')\n",
        "train_label = ToTensor()(train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqpr1D_kBwG2"
      },
      "outputs": [],
      "source": [
        "print(f\"The length of train dataset is: {len(train_ds)}\")\n",
        "print(f\"The size of the image is: {train_ds[0]['image'].shape} with type {type(train_ds[0]['image'])}\")\n",
        "print(f\"The size of the label is: {train_label.shape} with type {type(train_label)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = np.load('/content/pneumoniamnist/val_images.npy')\n",
        "val_labels = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "\n",
        "val_files = [{'image': img} for img in val_images]\n",
        "\n",
        "val_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),\n",
        "    ScaleIntensityd(keys=['image']),\n",
        "    EnsureTyped(keys=['image']),\n",
        "    # Resized(keys=[\"image\"],spatial_size=(32,32)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2,2]), # Changed BorderPad to BorderPadd\n",
        "])\n",
        "\n",
        "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "val_label = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "val_label = ToTensor()(val_label)"
      ],
      "metadata": {
        "id": "uyN0g7iztQvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The length of val dataset is: {len(val_ds)}\")\n",
        "print(f\"The size of the image is: {val_ds[0]['image'].shape} with type {type(val_ds[0]['image'])}\")\n",
        "print(f\"The size of the label is: {val_label.shape} with type {type(val_label)}\")"
      ],
      "metadata": {
        "id": "zy-QrlXnvaFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRVNZNHj8N-H"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmKmrDk6HMi9"
      },
      "outputs": [],
      "source": [
        "from monai.data import DataLoader\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yeaP_TGEQ7Y"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=list(zip(train_ds, train_label)),  # Use zip to create pairs of (image, label)\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P1sKftxH08Y"
      },
      "outputs": [],
      "source": [
        "print(len(train_loader))\n",
        "\n",
        "# Iterate through the DataLoader using a for loop\n",
        "for batch_data in train_loader:\n",
        "    # Access the batch data (images and labels)\n",
        "    images, labels = batch_data\n",
        "    # Now you can print or process the data in the batch\n",
        "    print(images['image'].shape, labels.shape)  # Example: print the shape of images and labels\n",
        "    break  # Exit the loop after processing the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfcQ11MyFmJS"
      },
      "outputs": [],
      "source": [
        "val_loader = DataLoader(\n",
        "    dataset=list(zip(val_ds, val_label)),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMrXOKsHMi_"
      },
      "source": [
        "## Model and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPOEMdXKlZax"
      },
      "outputs": [],
      "source": [
        "from monai.networks.nets import DenseNet\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.metrics import ROCAUCMetric\n",
        "import sklearn\n",
        "\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "if(device == \"cpu\"): print(\"using CPU\")\n",
        "\n",
        "model = DenseNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)     #Declare the model\n",
        "loss_function=DiceCELoss(to_onehot_y=True,lambda_dice=0,lambda_ce=1)           #Loss function declaration\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)\n",
        "max_epochs=5\n",
        "val_interval=1\n",
        "auc_metric = ROCAUCMetric()\n",
        "class_names = ['normal', 'pneumonia']\n",
        "\n",
        "from monai.transforms import AsDiscrete, Activations\n",
        "y_pred_trans = Activations(softmax=True)                          #added y_pred_trans for softmax\n",
        "y_trans = AsDiscrete(to_onehot=2)                                 #added y_trans for one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym1UHXv1HMi_"
      },
      "source": [
        "## Training & Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB8K4SkQ6M3N"
      },
      "source": [
        "* Below cell trains model on train dataset and validate the model on validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG7jmcLyHMi_"
      },
      "outputs": [],
      "source": [
        "from monai.data import decollate_batch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(max_epochs):                                                                   #Iteration of for loop through multiple epochs\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in tqdm(train_loader):                                                                              #Iteration of all the data in train loader\n",
        "        step += 1\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs[\"image\"].to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)                                                                                 #Predicting the outputs from the model\n",
        "        loss = loss_function(outputs, labels)                                                                   #Computing the loss for each batch\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")                                                  #Printing the computed loss after training\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:                                                                         #Iteration of all the data in val loader\n",
        "                val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)                                                                    #Computing the AUROC metric\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "            y_pred_class = torch.argmax(y_pred, dim=1)                          # Convert logits to class labels\n",
        "            acc_metric = accuracy_score(y.cpu().numpy(),y_pred_class.cpu().numpy())                             # Computing the accuracy\n",
        "            if result > best_metric:\n",
        "                best_metric = result\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
        "                f\" current accuracy: {acc_metric:.4f}\"\n",
        "                f\" best AUC: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "vL88y5ULJB-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"/content/best_metric_model.pth\"))\n",
        "\n",
        "#Setting the model to evaluation state\n",
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "    for val_data in val_loader:\n",
        "        val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "        y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "        y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "print(f\"The shape of y_pred is: {y_pred.shape}\")\n",
        "y_pred_class = torch.argmax(y_pred,dim=1)\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.shape}\")\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.unsqueeze(-1).shape}\")\n",
        "accuracy = accuracy_score(y_pred_class.cpu().numpy(),y.squeeze(-1).cpu().numpy())\n",
        "print(f\"Accuracy on validation set: {accuracy}\")\n",
        "y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "y_pred_onehot = [y_trans(i) for i in decollate_batch(y_pred_class.unsqueeze(-1), detach=False)]\n",
        "y_onehot = torch.stack(y_onehot)\n",
        "y_pred_onehot = torch.stack(y_pred_onehot)\n",
        "print(f\"The shape of y_pred_onehot is: {y_pred_onehot.shape}\")\n",
        "print(f\"The shape of y_onehot is: {y_onehot.shape}\")\n",
        "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "conf_matix_sklearn = confusion_matrix(y,y_pred_class)\n",
        "# print(f\"Confusion Matrix:\\n{conf_matix_sklearn}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y.cpu().numpy(), y_pred_class.cpu().numpy(), target_names=class_names))"
      ],
      "metadata": {
        "id": "X9SQdSSNXXBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "S_XBOyA6XY_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming conf_matix_sklearn is your confusion matrix from sklearn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matix_sklearn, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v7dUVj_dllaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Work\n",
        "\n",
        "**Methodology**\n",
        "The project explored six tasks to understand how different factors affect classification performance:\n",
        "\n",
        "**Task 1**: Impact of Model Architecture on Classification Performance\n",
        "\n",
        "**Task 2**: Evaluating the Influence of Loss Functions\n",
        "\n",
        "**Task 3**: Investigating the Effect of Image Resizing on Classification Accuracy\n",
        "\n",
        "**Task 4**: Assessing Training Variability in Deep Learning Models\n",
        "\n",
        "**Task 5**: Exploring the Role of Weight Initialization Strategies\n",
        "\n",
        "**Task 6**: Generalizability of Medical Image Classification Models to New Datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "Uj589t8gK51H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Changing the model"
      ],
      "metadata": {
        "id": "47azpMMwdsrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [MONAI Models](https://docs.monai.io/en/stable/networks.html)\n",
        "\n",
        "- Provides an overview of essential building blocks for deep learning models in medical imaging, including various layers, activation functions, and normalization techniques.\n",
        "\n",
        "- It also showcases how these components can be combined to create powerful network architectures for tasks like classification, segmentation, and generative modeling."
      ],
      "metadata": {
        "id": "unh27pAolaEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.nets import ResNet,EfficientNet, DenseNet121\n",
        "\n",
        "# model = ResNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "# model = EfficientNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=2).to(device)"
      ],
      "metadata": {
        "id": "gu84xfTbnci0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Torchvision Models](https://pytorch.org/vision/stable/models.html)\n",
        "\n",
        "1. **Provides a Variety of Pre-trained Models**:  The page lists various  models for image classification, object detection, video classification, and image segmentation,  including popular architectures like ResNet, AlexNet, VGG, and Inception. These pre-trained models can be used directly or fine-tuned for specific tasks.\n",
        "\n",
        "2. **Offers Flexibility with Weights**:  You can easily load pre-trained weights for these models, and even use a new Multi-weight support API (as of version 0.13) to load different weights into the existing model architectures. This allows for experimentation and customization.\n",
        "\n",
        "3. **[GitHub repository](https://github.com/pytorch/vision/blob/main/torchvision/models/)**: The source code for all the models are found here.\n"
      ],
      "metadata": {
        "id": "4FBP8EzWd01h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torchvision"
      ],
      "metadata": {
        "id": "05bygL2XfM1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "del model\n",
        "#Importing mobilenetV3\n",
        "from torchvision.models import mobilenet_v3_large\n",
        "\n",
        "# model_mobilenet = mobilenet_v3_small(input_channels=1,out_channels=2)\n",
        "# print(model_mobilenet)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = mobilenet_v3_large(pretrained=False)\n",
        "\n",
        "# Modify the first convolutional layer to accept 1 input channel\n",
        "model.features[0][0] = torch.nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "\n",
        "# Modify the classifier to output 2 classes\n",
        "model.classifier[3] = torch.nn.Linear(in_features=1280, out_features=2, bias=True)\n",
        "model.classifier[2] = torch.nn.Dropout(p=0.0, inplace=True)\n",
        "\n",
        "print(model)\n",
        "loss_function=DiceCELoss(to_onehot_y=True,lambda_dice=0,lambda_ce=1)\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)"
      ],
      "metadata": {
        "id": "HPvGzbRxfS6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v2\n",
        "del model\n",
        "# Load the pre-trained model\n",
        "model = mobilenet_v2(pretrained=False)\n",
        "\n",
        "# Modify the first convolutional layer to accept 1 input channel\n",
        "model.features[0][0] = torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "\n",
        "# Modify the classifier to output 2 classes\n",
        "model.classifier[1] = torch.nn.Linear(in_features=1280, out_features=2, bias=True)\n",
        "model.classifier[0] = torch.nn.Dropout(p=0.0, inplace=False)\n",
        "print(model)\n",
        "loss_function=DiceCELoss(to_onehot_y=True,lambda_dice=0,lambda_ce=1)\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)"
      ],
      "metadata": {
        "id": "0fQ-LflfIHwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet34\n",
        "\n",
        "model = resnet34(weights=True)\n",
        "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.fc = torch.nn.Linear(in_features=512, out_features=2, bias=True)\n",
        "print(model)\n",
        "loss_function=DiceCELoss(to_onehot_y=True,lambda_dice=0,lambda_ce=1)\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)"
      ],
      "metadata": {
        "id": "uc7fRsLhabnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training New Model"
      ],
      "metadata": {
        "id": "yn5aFGRcy1vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.data import decollate_batch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "max_epochs=5\n",
        "for epoch in range(max_epochs):                                                                   #Iteration of for loop through multiple epochs\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in tqdm(train_loader):                                                                              #Iteration of all the data in train loader\n",
        "        step += 1\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs[\"image\"].to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)                                                                                 #Predicting the outputs from the model\n",
        "        loss = loss_function(outputs, labels)                                                                   #Computing the loss for each batch\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")                                                  #Printing the computed loss after training\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:                                                                         #Iteration of all the data in val loader\n",
        "                val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)                                                                    #Computing the AUROC metric\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "            y_pred_class = torch.argmax(y_pred, dim=1)                          # Convert logits to class labels\n",
        "            acc_metric = accuracy_score(y.cpu().numpy(),y_pred_class.cpu().numpy())                             # Computing the accuracy\n",
        "            if result > best_metric:\n",
        "                best_metric = result\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_modelchange.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
        "                f\" current accuracy: {acc_metric:.4f}\"\n",
        "                f\" best AUC: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
      ],
      "metadata": {
        "id": "lG6F1dCmy8Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "schS7YuscHPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"/content/best_metric_model_modelchange.pth\"))\n",
        "\n",
        "#Setting the model to evaluation state\n",
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "    for val_data in val_loader:\n",
        "        val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "        y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "        y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "print(f\"The shape of y_pred is: {y_pred.shape}\")\n",
        "y_pred_class = torch.argmax(y_pred,dim=1)\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.shape}\")\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.unsqueeze(-1).shape}\")\n",
        "accuracy = accuracy_score(y_pred_class.cpu().numpy(),y.squeeze(-1).cpu().numpy())\n",
        "print(f\"Accuracy on validation set: {accuracy}\")\n",
        "y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "y_pred_onehot = [y_trans(i) for i in decollate_batch(y_pred_class.unsqueeze(-1), detach=False)]\n",
        "y_onehot = torch.stack(y_onehot)\n",
        "y_pred_onehot = torch.stack(y_pred_onehot)\n",
        "print(f\"The shape of y_pred_onehot is: {y_pred_onehot.shape}\")\n",
        "print(f\"The shape of y_onehot is: {y_onehot.shape}\")\n",
        "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "conf_matix_sklearn = confusion_matrix(y,y_pred_class)\n",
        "# print(f\"Confusion Matrix:\\n{conf_matix_sklearn}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y.cpu().numpy(), y_pred_class.cpu().numpy(), target_names=class_names))"
      ],
      "metadata": {
        "id": "PpNgRBQacGeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization"
      ],
      "metadata": {
        "id": "sINbbg3Jlr9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming conf_matix_sklearn is your confusion matrix from sklearn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matix_sklearn, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mR53w3JslvmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Changing loss function"
      ],
      "metadata": {
        "id": "E0-rGKGFms-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Torch lossses\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.nn import MultiMarginLoss\n",
        "\n"
      ],
      "metadata": {
        "id": "MRVzsM8oRCv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define batch size and number of classes\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "\n",
        "# Generate random tensors\n",
        "x = torch.rand(batch_size, num_classes)  # Probabilities\n",
        "y = torch.randint(0, num_classes, (batch_size,))  # Labels\n",
        "\n",
        "# Print shapes\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "\n",
        "# Define loss functions\n",
        "loss_fn_bce = nn.BCELoss()\n",
        "loss_fn_bce_logits = nn.BCEWithLogitsLoss()\n",
        "loss_fn_multimargin = nn.MultiMarginLoss()\n",
        "loss_fn_monai_ce = DiceCELoss(to_onehot_y=True, lambda_dice=0, lambda_ce=1)\n",
        "\n",
        "loss_bce = loss_fn_bce(torch.sigmoid(x), nn.functional.one_hot(y, num_classes).float())\n",
        "loss_bce_logits = loss_fn_bce_logits(x, nn.functional.one_hot(y, num_classes).float())\n",
        "loss_multimargin = loss_fn_multimargin(x, y)\n",
        "loss_monai_ce = loss_fn_monai_ce(x, y.unsqueeze(-1))\n",
        "\n",
        "# Print losses\n",
        "print(\"BCELoss:\", loss_bce)\n",
        "print(\"BCEWithLogitsLoss:\", loss_bce_logits)\n",
        "print(\"MultiMarginLoss:\", loss_multimargin)\n",
        "print(\"MONAI DiceCELoss:\", loss_monai_ce)"
      ],
      "metadata": {
        "id": "kDb46Jf3RcV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.nets import DenseNet\n",
        "#Importing FocalLoss from MONAI\n",
        "from monai.losses import FocalLoss\n",
        "\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "if(device == \"cpu\"): print(\"using CPU\")\n",
        "\n",
        "model = DenseNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "loss_function=FocalLoss(to_onehot_y=True)\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)\n",
        "max_epochs=5\n",
        "val_interval=1\n",
        "auc_metric = ROCAUCMetric()\n",
        "class_names = ['normal', 'pneumonia']\n",
        "\n",
        "from monai.transforms import AsDiscrete, Activations\n",
        "y_pred_trans = Activations(softmax=True)                          #added y_pred_trans for softmax\n",
        "y_trans = AsDiscrete(to_onehot=2)                                 #added y_trans for one_hot"
      ],
      "metadata": {
        "id": "4TIyRTkJm0WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model & Training"
      ],
      "metadata": {
        "id": "QED4y76DrKZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.data import decollate_batch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "max_epochs=5\n",
        "for epoch in range(max_epochs):                                                                   #Iteration of for loop through multiple epochs\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in tqdm(train_loader):                                                                              #Iteration of all the data in train loader\n",
        "        step += 1\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs[\"image\"].to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)                                                                                 #Predicting the outputs from the model\n",
        "        loss = loss_fn_multimargin(outputs, labels)                                                                   #Computing the loss for each batch\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")                                                  #Printing the computed loss after training\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:                                                                         #Iteration of all the data in val loader\n",
        "                val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)                                                                    #Computing the AUROC metric\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "            y_pred_class = torch.argmax(y_pred, dim=1)                          # Convert logits to class labels\n",
        "            acc_metric = accuracy_score(y.cpu().numpy(),y_pred_class.cpu().numpy())                             # Computing the accuracy\n",
        "            if result > best_metric:\n",
        "                best_metric = result\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_losfunctionchange.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
        "                f\" current accuracy: {acc_metric:.4f}\"\n",
        "                f\" best AUC: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
      ],
      "metadata": {
        "id": "Pje3YU95rC0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "Pa9mtMS3rieN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"/content/best_metric_model_losfunctionchange.pth\"))\n",
        "\n",
        "#Setting the model to evaluation state\n",
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "    for val_data in val_loader:\n",
        "        val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "        y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "        y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "print(f\"The shape of y_pred is: {y_pred.shape}\")\n",
        "y_pred_class = torch.argmax(y_pred,dim=1)\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.shape}\")\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.unsqueeze(-1).shape}\")\n",
        "accuracy = accuracy_score(y_pred_class.cpu().numpy(),y.squeeze(-1).cpu().numpy())\n",
        "print(f\"Accuracy on validation set: {accuracy}\")\n",
        "y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "y_pred_onehot = [y_trans(i) for i in decollate_batch(y_pred_class.unsqueeze(-1), detach=False)]\n",
        "y_onehot = torch.stack(y_onehot)\n",
        "y_pred_onehot = torch.stack(y_pred_onehot)\n",
        "print(f\"The shape of y_pred_onehot is: {y_pred_onehot.shape}\")\n",
        "print(f\"The shape of y_onehot is: {y_onehot.shape}\")\n",
        "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "conf_matix_sklearn = confusion_matrix(y,y_pred_class)\n",
        "# print(f\"Confusion Matrix:\\n{conf_matix_sklearn}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y.cpu().numpy(), y_pred_class.cpu().numpy(), target_names=class_names))"
      ],
      "metadata": {
        "id": "EIfEur7grm38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization"
      ],
      "metadata": {
        "id": "mZKBqMEDrw-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming conf_matix_sklearn is your confusion matrix from sklearn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matix_sklearn, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_M516Vc7rxpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Changing image dimensions"
      ],
      "metadata": {
        "id": "U6cbAD7ys7Ye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforms"
      ],
      "metadata": {
        "id": "XQ8GLnMvwSN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,  # Import LoadImaged for dictionary-based input\n",
        "    RandRotate,\n",
        "    RandFlip,\n",
        "    ToTensor,\n",
        "    EnsureChannelFirstd, # Use EnsureChannelFirstd to work with dictionary\n",
        "    ScaleIntensityd, # Use ScaleIntensityd to work with dictionary\n",
        "    EnsureTyped, # Add this\n",
        "    Resized,\n",
        "    BorderPadd\n",
        ")\n",
        "from monai.data import Dataset, NumpyReader\n",
        "\n",
        "# Define transforms for training data\n",
        "train_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),  # Add channel dimension to the image data using the 'image' key\n",
        "    ScaleIntensityd(keys=['image']),  # Rescale image pixel values using the 'image' key\n",
        "    EnsureTyped(keys=['image']),\n",
        "    Resized(keys=[\"image\"],spatial_size=(60,60)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2,2]),\n",
        "])\n",
        "\n",
        "train_ds = Dataset(data=train_dataset, transform=train_transforms)\n",
        "train_label = np.load('/content/pneumoniamnist/train_labels.npy')\n",
        "train_label = ToTensor()(train_label)\n",
        "\n",
        "\n",
        "\n",
        "val_images = np.load('/content/pneumoniamnist/val_images.npy')\n",
        "val_labels = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "\n",
        "val_files = [{'image': img} for img in val_images]\n",
        "\n",
        "val_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),\n",
        "    ScaleIntensityd(keys=['image']),\n",
        "    EnsureTyped(keys=['image']),\n",
        "    Resized(keys=[\"image\"],spatial_size=(60,60)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2,2]),\n",
        "])\n",
        "\n",
        "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "val_label = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "val_label = ToTensor()(val_label)"
      ],
      "metadata": {
        "id": "kJJR5EO-tAw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The length of train dataset is: {len(train_ds)}\")\n",
        "print(f\"The size of the image is: {train_ds[0]['image'].shape} with type {type(train_ds[0]['image'])}\")\n",
        "print(f\"The size of the label is: {train_label.shape} with type {type(train_label)}\")\n",
        "print(f\"The length of val dataset is: {len(val_ds)}\")\n",
        "print(f\"The size of the image is: {val_ds[0]['image'].shape} with type {type(val_ds[0]['image'])}\")\n",
        "print(f\"The size of the label is: {val_label.shape} with type {type(val_label)}\")"
      ],
      "metadata": {
        "id": "ExfJHdR5tsQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "szQ2YlmAwVrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=list(zip(train_ds, train_label)),  # Use zip to create pairs of (image, label)\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=list(zip(val_ds, val_label)),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "FIfk2Lp1wXX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model & Training"
      ],
      "metadata": {
        "id": "HgyMiXtgwImq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.nets import DenseNet\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.metrics import ROCAUCMetric\n",
        "import sklearn\n",
        "del model\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "if(device == \"cpu\"): print(\"using CPU\")\n",
        "\n",
        "model = DenseNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "loss_function=DiceCELoss(to_onehot_y=True,lambda_dice=0,lambda_ce=1)\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)\n",
        "max_epochs=1\n",
        "val_interval=1\n",
        "auc_metric = ROCAUCMetric()\n",
        "class_names = ['normal', 'pneumonia']\n",
        "\n",
        "from monai.transforms import AsDiscrete, Activations\n",
        "y_pred_trans = Activations(softmax=True)                          #added y_pred_trans for softmax\n",
        "y_trans = AsDiscrete(to_onehot=2)                                 #added y_trans for one_hot"
      ],
      "metadata": {
        "id": "4wxLZeEVwO7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "QNRJ3KjEwl_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.data import decollate_batch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "max_epochs=5\n",
        "\n",
        "\n",
        "for epoch in range(max_epochs):                                                                   #Iteration of for loop through multiple epochs\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in tqdm(train_loader):                                                                              #Iteration of all the data in train loader\n",
        "        step += 1\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs[\"image\"].to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)                                                                                 #Predicting the outputs from the model\n",
        "        loss = loss_function(outputs, labels)                                                                   #Computing the loss for each batch\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")                                                  #Printing the computed loss after training\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:                                                                         #Iteration of all the data in val loader\n",
        "                val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)                                                                    #Computing the AUROC metric\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "            y_pred_class = torch.argmax(y_pred, dim=1)                          # Convert logits to class labels\n",
        "            acc_metric = accuracy_score(y.cpu().numpy(),y_pred_class.cpu().numpy())                             # Computing the accuracy\n",
        "            if result > best_metric:\n",
        "                best_metric = result\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_imageresize.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
        "                f\" current accuracy: {acc_metric:.4f}\"\n",
        "                f\" best AUC: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
      ],
      "metadata": {
        "id": "uCkYHhGiwp0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "i8oEWZNtwrOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"/content/best_metric_model_imageresize.pth\"))\n",
        "\n",
        "#Setting the model to evaluation state\n",
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "    for val_data in val_loader:\n",
        "        val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "        y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "        y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "print(f\"The shape of y_pred is: {y_pred.shape}\")\n",
        "y_pred_class = torch.argmax(y_pred,dim=1)\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.shape}\")\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.unsqueeze(-1).shape}\")\n",
        "accuracy = accuracy_score(y_pred_class.cpu().numpy(),y.squeeze(-1).cpu().numpy())\n",
        "print(f\"Accuracy on validation set: {accuracy}\")\n",
        "y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "y_pred_onehot = [y_trans(i) for i in decollate_batch(y_pred_class.unsqueeze(-1), detach=False)]\n",
        "y_onehot = torch.stack(y_onehot)\n",
        "y_pred_onehot = torch.stack(y_pred_onehot)\n",
        "print(f\"The shape of y_pred_onehot is: {y_pred_onehot.shape}\")\n",
        "print(f\"The shape of y_onehot is: {y_onehot.shape}\")\n",
        "\n",
        "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "conf_matix_sklearn = confusion_matrix(y,y_pred_class)\n",
        "# print(f\"Confusion Matrix:\\n{conf_matix_sklearn}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y.cpu().numpy(), y_pred_class.cpu().numpy(), target_names=class_names))"
      ],
      "metadata": {
        "id": "Ie-nM4Nbws1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization"
      ],
      "metadata": {
        "id": "wVuoXMYzw7-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming conf_matix_sklearn is your confusion matrix from sklearn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matix_sklearn, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PDg1kUYQw-SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Observe Training Variability\n",
        "\n",
        "The first code has to be run three times to understand the variability in the performance on the model during three different runs"
      ],
      "metadata": {
        "id": "EM5fWBYyDiKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Changing weight initialization"
      ],
      "metadata": {
        "id": "jqXSd2WqD6hO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforms"
      ],
      "metadata": {
        "id": "J22hR8_2EKdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,  # Import LoadImaged for dictionary-based input\n",
        "    RandRotate,\n",
        "    RandFlip,\n",
        "    ToTensor,\n",
        "    EnsureChannelFirstd, # Use EnsureChannelFirstd to work with dictionary\n",
        "    ScaleIntensityd, # Use ScaleIntensityd to work with dictionary\n",
        "    EnsureTyped, # Add this\n",
        "    Resized,\n",
        "    BorderPadd # Use BorderPadd for dictionary-based input\n",
        ")\n",
        "from monai.data import Dataset, NumpyReader\n",
        "\n",
        "# Define transforms for training data\n",
        "train_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),  # Add channel dimension to the image data using the 'image' key\n",
        "    ScaleIntensityd(keys=['image']),  # Rescale image pixel values using the 'image' key\n",
        "    EnsureTyped(keys=['image']),\n",
        "    # Resized(keys=[\"image\"],spatial_size=(32,32)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2, 2]), # Use a list of two integers for padding (height, width) or a single integer for both.\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = Dataset(data=train_dataset, transform=train_transforms)\n",
        "train_label = np.load('/content/pneumoniamnist/train_labels.npy')\n",
        "train_label = ToTensor()(train_label)"
      ],
      "metadata": {
        "id": "hQgVlDdhEMTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The length of train dataset is: {len(train_ds)}\")\n",
        "print(f\"The size of the image is: {train_ds[0]['image'].shape} with type {type(train_ds[0]['image'])}\")\n",
        "print(f\"The size of the label is: {train_label.shape} with type {type(train_label)}\")"
      ],
      "metadata": {
        "id": "eBpMQfCAENLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = np.load('/content/pneumoniamnist/val_images.npy')\n",
        "val_labels = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "\n",
        "val_files = [{'image': img} for img in val_images]\n",
        "\n",
        "val_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),\n",
        "    ScaleIntensityd(keys=['image']),\n",
        "    EnsureTyped(keys=['image']),\n",
        "    # Resized(keys=[\"image\"],spatial_size=(32,32)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2,2]), # Changed BorderPad to BorderPadd\n",
        "])\n",
        "\n",
        "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "val_label = np.load('/content/pneumoniamnist/val_labels.npy')\n",
        "val_label = ToTensor()(val_label)"
      ],
      "metadata": {
        "id": "RtF974yjERL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The length of val dataset is: {len(val_ds)}\")\n",
        "print(f\"The size of the image is: {val_ds[0]['image'].shape} with type {type(val_ds[0]['image'])}\")\n",
        "print(f\"The size of the label is: {val_label.shape} with type {type(val_label)}\")"
      ],
      "metadata": {
        "id": "BbrJL0jiEVXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "l6x7wM-mEY1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=list(zip(train_ds, train_label)),  # Use zip to create pairs of (image, label)\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=list(zip(val_ds, val_label)),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "XR7l_-mKEbOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model parameters"
      ],
      "metadata": {
        "id": "HAneEG6hEgUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer Learning weight initialization"
      ],
      "metadata": {
        "id": "U7w8x0sbHhSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.nets import DenseNet121\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.metrics import ROCAUCMetric\n",
        "import sklearn\n",
        "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=2,pretrained=True).to(device)\n"
      ],
      "metadata": {
        "id": "D4WN-wvEHpr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kaiming Initialization"
      ],
      "metadata": {
        "id": "QAB0PODWUD-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = DenseNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "from torch.nn import init\n",
        "# Apply Kaiming initialization to convolutional layers\n",
        "for m in model.modules():\n",
        "    if isinstance(m, torch.nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')  # Adjust nonlinearity if needed\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "4KIEpc8rUJQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Initialization"
      ],
      "metadata": {
        "id": "iz0tkZH9VRAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = DenseNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "from torch.nn import init\n",
        "# Apply random initialization to convolutional layers\n",
        "for m in model.modules():\n",
        "    if isinstance(m, torch.nn.Conv2d):\n",
        "        init.xavier_uniform_(m.weight)  # Or init.uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "xZyvMp_xVW7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other initializations"
      ],
      "metadata": {
        "id": "LCtU0DbHVgfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function=DiceCELoss(to_onehot_y=True,lambda_dice=0,lambda_ce=1)\n",
        "optimizer= torch.optim.Adam(model.parameters(), 1e-3)\n",
        "max_epochs=1\n",
        "val_interval=1\n",
        "auc_metric = ROCAUCMetric()\n",
        "class_names = ['normal', 'pneumonia']\n",
        "\n",
        "from monai.transforms import AsDiscrete, Activations\n",
        "y_pred_trans = Activations(softmax=True)                          #added y_pred_trans for softmax\n",
        "y_trans = AsDiscrete(to_onehot=2)                                 #added y_trans for one_hot"
      ],
      "metadata": {
        "id": "yNMrtSGcVf-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "-U_YvXzKVxrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.data import decollate_batch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(max_epochs):                                                                   #Iteration of for loop through multiple epochs\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in tqdm(train_loader):                                                                              #Iteration of all the data in train loader\n",
        "        step += 1\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs[\"image\"].to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)                                                                                 #Predicting the outputs from the model\n",
        "        loss = loss_function(outputs, labels)                                                                   #Computing the loss for each batch\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")                                                  #Printing the computed loss after training\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:                                                                         #Iteration of all the data in val loader\n",
        "                val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)                                                                    #Computing the AUROC metric\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "            y_pred_class = torch.argmax(y_pred, dim=1)                          # Convert logits to class labels\n",
        "            acc_metric = accuracy_score(y.cpu().numpy(),y_pred_class.cpu().numpy())                             # Computing the accuracy\n",
        "            if result > best_metric:\n",
        "                best_metric = result\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), \"best_metric_model_initialization.pth\")\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
        "                f\" current accuracy: {acc_metric:.4f}\"\n",
        "                f\" best AUC: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
      ],
      "metadata": {
        "id": "u_s4CBWfV1r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "Hm1_JxifWU-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"/content/best_metric_model_initialization.pth\"))\n",
        "\n",
        "#Setting the model to evaluation state\n",
        "model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "    for val_data in val_loader:\n",
        "        val_images, val_labels = val_data[0][\"image\"].to(device), val_data[1].to(device)\n",
        "        y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "        y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "print(f\"The shape of y_pred is: {y_pred.shape}\")\n",
        "y_pred_class = torch.argmax(y_pred,dim=1)\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.shape}\")\n",
        "print(f\"The shape of y_pred_class is: {y_pred_class.unsqueeze(-1).shape}\")\n",
        "accuracy = accuracy_score(y_pred_class.cpu().numpy(),y.squeeze(-1).cpu().numpy())\n",
        "print(f\"Accuracy on validation set: {accuracy}\")\n",
        "y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "y_pred_onehot = [y_trans(i) for i in decollate_batch(y_pred_class.unsqueeze(-1), detach=False)]\n",
        "y_onehot = torch.stack(y_onehot)\n",
        "y_pred_onehot = torch.stack(y_pred_onehot)\n",
        "print(f\"The shape of y_pred_onehot is: {y_pred_onehot.shape}\")\n",
        "print(f\"The shape of y_onehot is: {y_onehot.shape}\")\n",
        "\n",
        "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "conf_matix_sklearn = confusion_matrix(y,y_pred_class)\n",
        "# print(f\"Confusion Matrix:\\n{conf_matix_sklearn}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y.cpu().numpy(), y_pred_class.cpu().numpy(), target_names=class_names))"
      ],
      "metadata": {
        "id": "j3N4-4ycWWoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization"
      ],
      "metadata": {
        "id": "-pkRVh4mWYpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming conf_matix_sklearn is your confusion matrix from sklearn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matix_sklearn, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fU_XwpwtWau6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generalizability"
      ],
      "metadata": {
        "id": "IzzrM7xEWkdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from medmnist import ChestMNIST"
      ],
      "metadata": {
        "id": "HVmIIPNBWnP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = ChestMNIST(root = '/content/',split='test', download=True)"
      ],
      "metadata": {
        "id": "bALHaEsRPdHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_test.info)"
      ],
      "metadata": {
        "id": "lbLx9SSvYqCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/chestmnist.npz -d /content/chestmnist"
      ],
      "metadata": {
        "id": "eG75KvMOTLWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from monai.networks.nets import DenseNet\n",
        "from monai.transforms import Activations, AsDiscrete\n",
        "from monai.data import decollate_batch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load test data and labels\n",
        "test_images = np.load('/content/chestmnist/val_images.npy')\n",
        "test_labels = np.load('/content/chestmnist/val_labels.npy')\n",
        "\n",
        "# Assuming you have a suitable transform for test data (similar to val_transforms)\n",
        "test_files = [{'image': i} for i in test_images]\n",
        "\n",
        "test_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    EnsureChannelFirstd(keys=['image'], channel_dim=\"no_channel\"),\n",
        "    ScaleIntensityd(keys=['image']),\n",
        "    EnsureTyped(keys=['image']),\n",
        "    # Resized(keys=[\"image\"],spatial_size=(32,32)),\n",
        "    BorderPadd(keys=[\"image\"],spatial_border=[2,2]), # Changed BorderPad to BorderPadd\n",
        "    ToTensor(),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "b8uCDnSqUnzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the min and max of the test_label array\n",
        "print(f\"Shape of the test_images: {test_images.shape}\")\n",
        "print(f\"Shape of test_labels: {test_labels.shape}\")\n",
        "print(f\"Min of test_labels: {np.min(test_labels)}\")\n",
        "print(f\"Max of test_labels: {np.max(test_labels)}\")"
      ],
      "metadata": {
        "id": "URe1QuoiXfjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test_labels = np.zeros((test_labels.shape[0], 1), dtype=int)\n",
        "\n",
        "for i in range(test_labels.shape[0]):\n",
        "    # Iterate through each element in the row of test_labels\n",
        "    # and set the corresponding value in new_test_labels based on the condition\n",
        "    for j in range(test_labels.shape[1]):\n",
        "        if test_labels[i][j] == 1 and j == 6:         # Check if the element is 1 and at index 6\n",
        "            new_test_labels[i] = 1  # Column 1 (position '6')\n",
        "            break # Exit the loop to go to the next row of test_labels\n",
        "\n",
        "    for j in range(test_labels.shape[1]):\n",
        "        if test_labels[i][j] == 1 and j == 7:         # Check if the element is 1 and at index 7\n",
        "            new_test_labels[i] = 1  # Column 1 (position '6')\n",
        "            break # Exit the loop to go to the next row of test_labels\n",
        "\n",
        "print(f\"Shape of the new test labels: {new_test_labels.shape}\")\n",
        "# You can now save new_test_labels to a file if needed\n",
        "# np.save('new_test_labels.npy', new_test_labels)"
      ],
      "metadata": {
        "id": "VfWYhghFdUY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "\n",
        "test_label = ToTensor()(new_test_labels)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=list(zip(test_ds, test_label)),\n",
        "    batch_size=32,  # Adjust batch size as needed\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DenseNet(spatial_dims=2, in_channels=1, out_channels=2).to(device)\n",
        "model.load_state_dict(torch.load(\"/content/best_metric_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "y_pred_trans = Activations(softmax=True)\n",
        "y_trans = AsDiscrete(to_onehot=2)\n",
        "class_names = ['Normal', 'Pneumonia']\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "    y = torch.tensor([], dtype=torch.long, device=device)\n",
        "    for test_data in test_loader:\n",
        "        test_images, test_labels = test_data[0][\"image\"].to(device), test_data[1].to(device)\n",
        "        y_pred = torch.cat([y_pred, model(test_images)], dim=0)\n",
        "        y = torch.cat([y, test_labels], dim=0)\n",
        "\n",
        "print(f\"The shape of y_pred is: {y_pred.shape}\")\n",
        "print(f\"The shape of y is: {y.shape}\")\n",
        "y_pred_class = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "print(classification_report(y.cpu().numpy(), y_pred_class.cpu().numpy(), target_names=class_names))\n",
        "\n",
        "conf_matrix = confusion_matrix(y.cpu().numpy(), y_pred_class.cpu().numpy())\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DZyBkSZ1WMJN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}